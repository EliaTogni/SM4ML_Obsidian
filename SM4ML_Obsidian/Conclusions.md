Both the multi-layered neural network and the Convolutional Neural Network demonstrated promising performance in terms of Zero-One loss and accuracy for both the original and augmented datasets. However, to obtain more accurate and conclusive results, it is essential to run the models using greater computational power. This would enable to conduct more experiments and implement a more refined tuning approach. Specifically, it would allow for an increase in the number of epochs and the number and size of the layers, which is not feasible within the constraints of the Google Colab environment. Enhanced computational resources would facilitate deeper exploration and optimization of the models, leading to potentially significant improvements in their performance.
Concerning my results, they showed that it is possible to obtain good results (besides the overfitting) in the binary classification task with the convolutional neural network, while the multi-layered network showed results far from convincing.
==The segmentation task, whose objective was to delete non relevant details, showed better results in the MLNN, making the images too simple for the Convolutional one.==
The augmented dataset proved to be the most effective, as it enhanced the network's ability to understand the data by introducing 'beneficial noise.' This noise helps the network learn truly relevant features by providing a more varied and representative set of training examples. As a result, the augmented dataset not only improved the learning process but also played a crucial role in reducing overfitting across all tested architectures. By exposing the model to a broader range of scenarios during training, data augmentation has ensured the model to generalize better to unseen data, thus improving its overall robustness and performance.
# Future Work and Improvements
A future experiment could consider applying both augmentation and segmentation to the dataset to analyze the changes in the metrics of interest. By combining these two techniques, it might be possible to enhance the model's performance further. Augmentation can increase the diversity of the training data, helping the model to generalize better, while segmentation can focus on the most relevant parts of the images, potentially improving the model's ability to identify key features. This combined approach could lead to improvements in various performance metrics such as the considered ones, providing a more comprehensive understanding of the model's capabilities and limitations. Additionally, experimenting with different combinations and sequences of these techniques could offer insights into the optimal preprocessing strategy for this specific classification task

-----